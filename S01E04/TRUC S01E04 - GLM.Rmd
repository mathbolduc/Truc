---
title: "TRUC S01E04 - GLM"
author: |
  | Par Géraldine LO SIOU (CPS), Ariinui TERIITEHAU, Mathieu BOLDUC (ISPF)
  
date: "Le 18 mai 2021"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scoll: no
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.path="Figs/",dev="png",echo=T, warning=F, message=F)
```


# Simple Linear Regression {.tabset .tabset-fade .tabset-pills}
Y = B0 + B1 X + E  
Assumptions : E = these errors are independent, normal with mean 0 and common variance squared(sigma)  

## Le Dataset
```{r ImportData}
# Importing the dataset
dataset = read.csv("Salary_Data.csv")
print(dataset)
```

## Echantillons d'apprentissage et test
Splitting the dataset into the Training set and Test set  
  
Reminder : 

*  The training set is a subset of data on which the model will learn how to predict the dependent variable given the independent variables. 
*  The test set is the remaining subset of data, on which we can evaluate the model to see if it predicts correctly, given the independent variables.


```{r ech}
# install.packages('caTools')
library(caTools)
set.seed(123)
# Splitting on the dependent variable : to have well distributed values of the dependent variable in the training and test sets.
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Echantillon d'apprentissage
print(training_set)
# Echantillon test
print(test_set)
```


## Régression
Fitting Simple Linear Regression to the Training set

```{r reglin}
regressor = lm(formula = Salary ~ YearsExperience,
               data = training_set)
summary(regressor)
```

## Prediction
Predicting the Test set results

```{r predlin}
y_pred = predict(regressor, newdata = test_set)
print(y_pred)
```

## Visualisation des résultats

```{r vizlin}
# Visualising the Training set results
# install.packages("rlang")
# install.packages("ggplot2")
library(ggplot2)
ggplot() +
  geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
             colour = 'red') +
  geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
            colour = 'blue') +
  ggtitle('Salary vs Experience (Training set)') +
  xlab('Years of experience') +
  ylab('Salary')

# Visualising the Test set results
library(ggplot2)
ggplot() +
  geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
             colour = 'red') +
  geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
            colour = 'blue') +
  ggtitle('Salary vs Experience (Test set)') +
  xlab('Years of experience') +
  ylab('Salary')


```


# Polynomial Regression   {.tabset .tabset-fade .tabset-pills}
Y = B0 + B1 X1 + B2 X1^2 + B3 X1^3 + B4 X1^4 + E

## Le Dataset
```{r ImportDataPol}
# Importing the dataset
dataset = read.csv("Position_Salaries.csv")
dataset = dataset[2:3]
print(dataset)

```

## Régression
In this example, we are not splitting the dataset, just because we just want to show the difference between the linear regression vs polynomial regression.

```{r regPol}
# Fitting Linear Regression to the dataset
lin_reg = lm(formula = Salary ~ .,
             data = dataset)
summary(lin_reg)

# Fitting Polynomial Regression to the dataset
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm(formula = Salary ~ .,
              data = dataset)
summary(poly_reg)

```


## Visualisation des résultats

```{r vizPol}
# Visualising the Linear Regression results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
  geom_point(aes(x = dataset$Level, y = dataset$Salary),
             colour = 'red') +
  geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)),
            colour = 'blue') +
  ggtitle('Linear Regression') +
  xlab('Level') +
  ylab('Salary')

# Visualising the Polynomial Regression results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
  geom_point(aes(x = dataset$Level, y = dataset$Salary),
             colour = 'red') +
  geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)),
            colour = 'blue') +
  ggtitle('Polynomial Regression') +
  xlab('Level') +
  ylab('Salary')


```



# Logistic Regression  {.tabset .tabset-fade .tabset-pills}

## Le Dataset
```{r ImportDataLog}
# Importing the dataset
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[3:5]

# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))

head(dataset)
```

## Echantillons d'apprentissage et test
Splitting the dataset into the Training set and Test set

```{r echLog}
# install.packages('caTools')
library(caTools)
library(data.table)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)

# Feature Scaling : Feature scaling is applied here on both the training and test sets as features could be on different scales. Indeed in some machine learning models, feature scaling is used to avoid some features to be dominated by others features in such a way that the dominated features are not considered in the machine learning models
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])

# Echantillon d'apprentissage
head(training_set)
# Echantillon test
head(test_set)
```


## Régression
Fitting Logistic Regression to the Training set
```{r regLog}
classifier = glm(formula = Purchased ~ .,
                 family = binomial,
                 data = training_set)
summary(classifier)
```

## Prediction
Predicting the Test set results

```{r predLog}
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])

# inclure la courbe ROC afin de choisir où couper pour la probabilité

y_pred = ifelse(prob_pred > 0.5, 1, 0)

# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred > 0.5)
print(cm)

```

## Visualisation des résultats

On doit revoir la viz

```{r vizLog}
# Visualising the Training set results
# Library « ElemStatLearn » got archived :
# go to : https://cran.r-project.org/src/contrib/Archive/ElemStatLearn/
# download latest version
# in Rstudio, go to « tools » > « install packages »
# library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic Regression (Training set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))

# Visualising the Test set results
# library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
     main = 'Logistic Regression (Test set)',
     xlab = 'Age', ylab = 'Estimated Salary',
     xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))

```

<!-- #  {.tabset .tabset-fade .tabset-pills} -->

<!-- ## Le Dataset -->
<!-- ```{r ImportData} -->
<!-- ``` -->

<!-- ## Echantillons d'apprentissage et test -->

<!-- ```{r ech} -->
<!-- ``` -->


<!-- ## Régression -->

<!-- ```{r reglin} -->
<!-- ``` -->

<!-- ## Prediction -->
<!-- Predicting the Test set results -->

<!-- ```{r predlin} -->
<!-- ``` -->

<!-- ## Visualisation des résultats -->

<!-- ```{r vizlin} -->

<!-- ``` -->


